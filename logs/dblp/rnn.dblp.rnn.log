2023-05-14 02:10:27,913 root         INFO     Namespace(data_path='dblp', expt_dir='./experiment/baseline_lstm', log_level='info', model='rnn')
2023-05-14 02:10:27,914 sentence_transformers.SentenceTransformer INFO     Load pretrained SentenceTransformer: all-MiniLM-L6-v2
2023-05-14 02:10:28,232 sentence_transformers.SentenceTransformer INFO     Use pytorch device: cuda
2023-05-14 02:10:30,467 seq2seq.trainer.supervised_trainer INFO     Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
), Scheduler: None
2023-05-14 02:10:41,351 seq2seq.trainer.supervised_trainer INFO     Progress: 3%, Train RMSE Loss: 0.0185
2023-05-14 02:10:46,371 seq2seq.trainer.supervised_trainer INFO     Progress: 4%, Train RMSE Loss: 0.0061
2023-05-14 02:10:51,485 seq2seq.trainer.supervised_trainer INFO     Progress: 6%, Train RMSE Loss: 0.0058
2023-05-14 02:10:56,673 seq2seq.trainer.supervised_trainer INFO     Progress: 8%, Train RMSE Loss: 0.0056
2023-05-14 02:11:01,952 seq2seq.trainer.supervised_trainer INFO     Progress: 9%, Train RMSE Loss: 0.0052
2023-05-14 02:11:11,204 seq2seq.trainer.supervised_trainer INFO     
Finished epoch 1: Train RMSE Loss: 0.0068, Dev RMSE Loss: 0.1305, Test RMSE Loss: 0.1318
2023-05-14 02:11:16,126 seq2seq.trainer.supervised_trainer INFO     Progress: 11%, Train RMSE Loss: 0.0053
2023-05-14 02:11:21,395 seq2seq.trainer.supervised_trainer INFO     Progress: 13%, Train RMSE Loss: 0.0048
2023-05-14 02:11:26,522 seq2seq.trainer.supervised_trainer INFO     Progress: 14%, Train RMSE Loss: 0.0048
2023-05-14 02:11:31,706 seq2seq.trainer.supervised_trainer INFO     Progress: 16%, Train RMSE Loss: 0.0048
2023-05-14 02:11:37,037 seq2seq.trainer.supervised_trainer INFO     Progress: 18%, Train RMSE Loss: 0.0046
2023-05-14 02:11:42,212 seq2seq.trainer.supervised_trainer INFO     Progress: 19%, Train RMSE Loss: 0.0044
2023-05-14 02:11:52,023 seq2seq.trainer.supervised_trainer INFO     
Finished epoch 2: Train RMSE Loss: 0.0048, Dev RMSE Loss: 0.1305, Test RMSE Loss: 0.1318
2023-05-14 02:11:56,604 seq2seq.trainer.supervised_trainer INFO     Progress: 21%, Train RMSE Loss: 0.0045
2023-05-14 02:12:01,722 seq2seq.trainer.supervised_trainer INFO     Progress: 23%, Train RMSE Loss: 0.0042
2023-05-14 02:12:06,938 seq2seq.trainer.supervised_trainer INFO     Progress: 24%, Train RMSE Loss: 0.0041
2023-05-14 02:12:12,276 seq2seq.trainer.supervised_trainer INFO     Progress: 26%, Train RMSE Loss: 0.0041
2023-05-14 02:12:17,510 seq2seq.trainer.supervised_trainer INFO     Progress: 27%, Train RMSE Loss: 0.0041
2023-05-14 02:12:22,616 seq2seq.trainer.supervised_trainer INFO     Progress: 29%, Train RMSE Loss: 0.0040
2023-05-14 02:12:32,582 seq2seq.trainer.supervised_trainer INFO     
Finished epoch 3: Train RMSE Loss: 0.0041, Dev RMSE Loss: 0.1305, Test RMSE Loss: 0.1318
2023-05-14 02:12:36,717 seq2seq.trainer.supervised_trainer INFO     Progress: 31%, Train RMSE Loss: 0.0041
2023-05-14 02:12:41,801 seq2seq.trainer.supervised_trainer INFO     Progress: 32%, Train RMSE Loss: 0.0039
2023-05-14 02:12:47,432 seq2seq.trainer.supervised_trainer INFO     Progress: 34%, Train RMSE Loss: 0.0037
2023-05-14 02:12:52,580 seq2seq.trainer.supervised_trainer INFO     Progress: 36%, Train RMSE Loss: 0.0038
2023-05-14 02:12:57,684 seq2seq.trainer.supervised_trainer INFO     Progress: 37%, Train RMSE Loss: 0.0037
2023-05-14 02:13:02,761 seq2seq.trainer.supervised_trainer INFO     Progress: 39%, Train RMSE Loss: 0.0036
2023-05-14 02:13:13,162 seq2seq.trainer.supervised_trainer INFO     
Finished epoch 4: Train RMSE Loss: 0.0038, Dev RMSE Loss: 0.1305, Test RMSE Loss: 0.1318
2023-05-14 02:13:16,916 seq2seq.trainer.supervised_trainer INFO     Progress: 41%, Train RMSE Loss: 0.0034
2023-05-14 02:13:22,459 seq2seq.trainer.supervised_trainer INFO     Progress: 42%, Train RMSE Loss: 0.0033
2023-05-14 02:13:27,579 seq2seq.trainer.supervised_trainer INFO     Progress: 44%, Train RMSE Loss: 0.0033
2023-05-14 02:13:32,771 seq2seq.trainer.supervised_trainer INFO     Progress: 46%, Train RMSE Loss: 0.0032
2023-05-14 02:13:37,836 seq2seq.trainer.supervised_trainer INFO     Progress: 47%, Train RMSE Loss: 0.0032
2023-05-14 02:13:43,111 seq2seq.trainer.supervised_trainer INFO     Progress: 49%, Train RMSE Loss: 0.0030
2023-05-14 02:13:53,862 seq2seq.trainer.supervised_trainer INFO     
Finished epoch 5: Train RMSE Loss: 0.0032, Dev RMSE Loss: 0.1305, Test RMSE Loss: 0.1318
2023-05-14 02:13:57,456 seq2seq.trainer.supervised_trainer INFO     Progress: 51%, Train RMSE Loss: 0.0031
2023-05-14 02:14:02,574 seq2seq.trainer.supervised_trainer INFO     Progress: 52%, Train RMSE Loss: 0.0030
2023-05-14 02:14:07,676 seq2seq.trainer.supervised_trainer INFO     Progress: 54%, Train RMSE Loss: 0.0029
2023-05-14 02:14:12,911 seq2seq.trainer.supervised_trainer INFO     Progress: 55%, Train RMSE Loss: 0.0030
2023-05-14 02:14:17,971 seq2seq.trainer.supervised_trainer INFO     Progress: 57%, Train RMSE Loss: 0.0030
2023-05-14 02:14:23,208 seq2seq.trainer.supervised_trainer INFO     Progress: 59%, Train RMSE Loss: 0.0032
2023-05-14 02:14:34,838 seq2seq.trainer.supervised_trainer INFO     
Finished epoch 6: Train RMSE Loss: 0.0030, Dev RMSE Loss: 0.1305, Test RMSE Loss: 0.1318
2023-05-14 02:14:37,644 seq2seq.trainer.supervised_trainer INFO     Progress: 60%, Train RMSE Loss: 0.0030
2023-05-14 02:14:42,812 seq2seq.trainer.supervised_trainer INFO     Progress: 62%, Train RMSE Loss: 0.0031
2023-05-14 02:14:47,967 seq2seq.trainer.supervised_trainer INFO     Progress: 64%, Train RMSE Loss: 0.0028
2023-05-14 02:14:53,182 seq2seq.trainer.supervised_trainer INFO     Progress: 65%, Train RMSE Loss: 0.0027
2023-05-14 02:14:58,364 seq2seq.trainer.supervised_trainer INFO     Progress: 67%, Train RMSE Loss: 0.0029
2023-05-14 02:15:03,548 seq2seq.trainer.supervised_trainer INFO     Progress: 69%, Train RMSE Loss: 0.0029
2023-05-14 02:15:15,529 seq2seq.trainer.supervised_trainer INFO     
Finished epoch 7: Train RMSE Loss: 0.0029, Dev RMSE Loss: 0.1305, Test RMSE Loss: 0.1318
2023-05-14 02:15:18,102 seq2seq.trainer.supervised_trainer INFO     Progress: 70%, Train RMSE Loss: 0.0026
2023-05-14 02:15:23,355 seq2seq.trainer.supervised_trainer INFO     Progress: 72%, Train RMSE Loss: 0.0028
2023-05-14 02:15:28,492 seq2seq.trainer.supervised_trainer INFO     Progress: 74%, Train RMSE Loss: 0.0028
2023-05-14 02:15:33,576 seq2seq.trainer.supervised_trainer INFO     Progress: 75%, Train RMSE Loss: 0.0026
2023-05-14 02:15:38,721 seq2seq.trainer.supervised_trainer INFO     Progress: 77%, Train RMSE Loss: 0.0026
2023-05-14 02:15:43,847 seq2seq.trainer.supervised_trainer INFO     Progress: 78%, Train RMSE Loss: 0.0028
2023-05-14 02:15:56,112 seq2seq.trainer.supervised_trainer INFO     
Finished epoch 8: Train RMSE Loss: 0.0027, Dev RMSE Loss: 0.1305, Test RMSE Loss: 0.1318
2023-05-14 02:15:58,277 seq2seq.trainer.supervised_trainer INFO     Progress: 80%, Train RMSE Loss: 0.0025
2023-05-14 02:16:03,374 seq2seq.trainer.supervised_trainer INFO     Progress: 82%, Train RMSE Loss: 0.0028
2023-05-14 02:16:08,609 seq2seq.trainer.supervised_trainer INFO     Progress: 83%, Train RMSE Loss: 0.0026
2023-05-14 02:16:13,779 seq2seq.trainer.supervised_trainer INFO     Progress: 85%, Train RMSE Loss: 0.0026
2023-05-14 02:16:18,972 seq2seq.trainer.supervised_trainer INFO     Progress: 87%, Train RMSE Loss: 0.0027
2023-05-14 02:16:24,299 seq2seq.trainer.supervised_trainer INFO     Progress: 88%, Train RMSE Loss: 0.0026
2023-05-14 02:16:35,895 seq2seq.trainer.supervised_trainer INFO     
Finished epoch 9: Train RMSE Loss: 0.0026, Dev RMSE Loss: 0.1304, Test RMSE Loss: 0.1318
2023-05-14 02:16:37,566 seq2seq.trainer.supervised_trainer INFO     Progress: 90%, Train RMSE Loss: 0.0024
2023-05-14 02:16:42,755 seq2seq.trainer.supervised_trainer INFO     Progress: 92%, Train RMSE Loss: 0.0025
2023-05-14 02:16:47,822 seq2seq.trainer.supervised_trainer INFO     Progress: 93%, Train RMSE Loss: 0.0025
2023-05-14 02:16:52,844 seq2seq.trainer.supervised_trainer INFO     Progress: 95%, Train RMSE Loss: 0.0023
2023-05-14 02:16:58,046 seq2seq.trainer.supervised_trainer INFO     Progress: 97%, Train RMSE Loss: 0.0024
2023-05-14 02:17:03,515 seq2seq.trainer.supervised_trainer INFO     Progress: 98%, Train RMSE Loss: 0.0026
2023-05-14 02:17:35,978 seq2seq.trainer.supervised_trainer INFO     
Finished epoch 10: Train RMSE Loss: 0.0025, Dev RMSE Loss: 0.1305, Test RMSE Loss: 0.1318
Train RMSE Loss from Evaluator: 0.1312
------Hyper-parameters------
model_name: rnn, batch_size: 64, hidden_size: 32, learning_rate: 0.001, num_epochs: 10, num_layers: 3, dropout_rate: 0.1, teacher_forcing_ratio: 1
input_size: 128, kernel_size: 3, num_head: 2, use_adamw: False
use_sbert = False, use_sbert_seq = False, in_len: 4, out_len: 5
----------------------------
--------------Best Model:--------------
Epoch 9, Train RMSE Loss: 0.1312, Dev RMSE Loss: 0.1304, Test RMSE Loss: 0.1318
---------------------------------------
