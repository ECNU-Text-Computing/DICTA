2023-05-14 01:18:30,704 root         INFO     Namespace(data_path='dblp', expt_dir='./experiment/baseline_rnn', log_level='info', model='cnn')
2023-05-14 01:18:30,704 sentence_transformers.SentenceTransformer INFO     Load pretrained SentenceTransformer: all-MiniLM-L6-v2
2023-05-14 01:18:31,065 sentence_transformers.SentenceTransformer INFO     Use pytorch device: cuda
2023-05-14 01:18:33,274 seq2seq.trainer.supervised_trainer INFO     Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
), Scheduler: None
2023-05-14 01:18:47,141 seq2seq.trainer.supervised_trainer INFO     Progress: 3%, Train RMSE Loss: 0.0831
2023-05-14 01:18:53,299 seq2seq.trainer.supervised_trainer INFO     Progress: 4%, Train RMSE Loss: 0.0391
2023-05-14 01:18:59,362 seq2seq.trainer.supervised_trainer INFO     Progress: 6%, Train RMSE Loss: 0.0376
2023-05-14 01:19:06,583 seq2seq.trainer.supervised_trainer INFO     Progress: 8%, Train RMSE Loss: 0.0375
2023-05-14 01:19:13,901 seq2seq.trainer.supervised_trainer INFO     Progress: 9%, Train RMSE Loss: 0.0352
2023-05-14 01:19:33,269 seq2seq.trainer.supervised_trainer INFO     
Finished epoch 1: Train RMSE Loss: 0.0387, Dev RMSE Loss: 0.1544, Test RMSE Loss: 0.1557
2023-05-14 01:19:40,339 seq2seq.trainer.supervised_trainer INFO     Progress: 11%, Train RMSE Loss: 0.0376
2023-05-14 01:19:47,699 seq2seq.trainer.supervised_trainer INFO     Progress: 13%, Train RMSE Loss: 0.0367
2023-05-14 01:19:54,614 seq2seq.trainer.supervised_trainer INFO     Progress: 14%, Train RMSE Loss: 0.0354
2023-05-14 01:20:02,063 seq2seq.trainer.supervised_trainer INFO     Progress: 16%, Train RMSE Loss: 0.0377
2023-05-14 01:20:09,629 seq2seq.trainer.supervised_trainer INFO     Progress: 18%, Train RMSE Loss: 0.0387
2023-05-14 01:20:17,212 seq2seq.trainer.supervised_trainer INFO     Progress: 19%, Train RMSE Loss: 0.0367
2023-05-14 01:20:36,983 seq2seq.trainer.supervised_trainer INFO     
Finished epoch 2: Train RMSE Loss: 0.0373, Dev RMSE Loss: 0.1405, Test RMSE Loss: 0.1419
2023-05-14 01:20:43,309 seq2seq.trainer.supervised_trainer INFO     Progress: 21%, Train RMSE Loss: 0.0383
2023-05-14 01:20:50,695 seq2seq.trainer.supervised_trainer INFO     Progress: 23%, Train RMSE Loss: 0.0380
2023-05-14 01:20:58,200 seq2seq.trainer.supervised_trainer INFO     Progress: 24%, Train RMSE Loss: 0.0366
2023-05-14 01:21:05,846 seq2seq.trainer.supervised_trainer INFO     Progress: 26%, Train RMSE Loss: 0.0377
2023-05-14 01:21:13,299 seq2seq.trainer.supervised_trainer INFO     Progress: 27%, Train RMSE Loss: 0.0386
2023-05-14 01:21:20,631 seq2seq.trainer.supervised_trainer INFO     Progress: 29%, Train RMSE Loss: 0.0361
2023-05-14 01:21:40,381 seq2seq.trainer.supervised_trainer INFO     
Finished epoch 3: Train RMSE Loss: 0.0374, Dev RMSE Loss: 0.1508, Test RMSE Loss: 0.1521
2023-05-14 01:21:46,386 seq2seq.trainer.supervised_trainer INFO     Progress: 31%, Train RMSE Loss: 0.0371
2023-05-14 01:21:53,789 seq2seq.trainer.supervised_trainer INFO     Progress: 32%, Train RMSE Loss: 0.0370
2023-05-14 01:22:01,348 seq2seq.trainer.supervised_trainer INFO     Progress: 34%, Train RMSE Loss: 0.0355
2023-05-14 01:22:08,835 seq2seq.trainer.supervised_trainer INFO     Progress: 36%, Train RMSE Loss: 0.0359
2023-05-14 01:22:16,457 seq2seq.trainer.supervised_trainer INFO     Progress: 37%, Train RMSE Loss: 0.0362
2023-05-14 01:22:23,701 seq2seq.trainer.supervised_trainer INFO     Progress: 39%, Train RMSE Loss: 0.0366
2023-05-14 01:22:42,636 seq2seq.trainer.supervised_trainer INFO     
Finished epoch 4: Train RMSE Loss: 0.0365, Dev RMSE Loss: 0.1493, Test RMSE Loss: 0.1507
2023-05-14 01:22:48,285 seq2seq.trainer.supervised_trainer INFO     Progress: 41%, Train RMSE Loss: 0.0369
2023-05-14 01:22:55,843 seq2seq.trainer.supervised_trainer INFO     Progress: 42%, Train RMSE Loss: 0.0385
2023-05-14 01:23:03,960 seq2seq.trainer.supervised_trainer INFO     Progress: 44%, Train RMSE Loss: 0.0339
2023-05-14 01:23:13,205 seq2seq.trainer.supervised_trainer INFO     Progress: 46%, Train RMSE Loss: 0.0357
2023-05-14 01:23:23,149 seq2seq.trainer.supervised_trainer INFO     Progress: 47%, Train RMSE Loss: 0.0347
2023-05-14 01:23:34,229 seq2seq.trainer.supervised_trainer INFO     Progress: 49%, Train RMSE Loss: 0.0365
2023-05-14 01:24:10,613 seq2seq.trainer.supervised_trainer INFO     
Finished epoch 5: Train RMSE Loss: 0.0361, Dev RMSE Loss: 0.1440, Test RMSE Loss: 0.1453
2023-05-14 01:24:17,478 seq2seq.trainer.supervised_trainer INFO     Progress: 51%, Train RMSE Loss: 0.0371
2023-05-14 01:24:28,052 seq2seq.trainer.supervised_trainer INFO     Progress: 52%, Train RMSE Loss: 0.0349
2023-05-14 01:24:39,512 seq2seq.trainer.supervised_trainer INFO     Progress: 54%, Train RMSE Loss: 0.0358
2023-05-14 01:24:49,873 seq2seq.trainer.supervised_trainer INFO     Progress: 55%, Train RMSE Loss: 0.0353
2023-05-14 01:25:00,610 seq2seq.trainer.supervised_trainer INFO     Progress: 57%, Train RMSE Loss: 0.0355
2023-05-14 01:25:12,440 seq2seq.trainer.supervised_trainer INFO     Progress: 59%, Train RMSE Loss: 0.0376
2023-05-14 01:25:47,814 seq2seq.trainer.supervised_trainer INFO     
Finished epoch 6: Train RMSE Loss: 0.0363, Dev RMSE Loss: 0.1413, Test RMSE Loss: 0.1426
2023-05-14 01:25:53,794 seq2seq.trainer.supervised_trainer INFO     Progress: 60%, Train RMSE Loss: 0.0374
2023-05-14 01:26:04,796 seq2seq.trainer.supervised_trainer INFO     Progress: 62%, Train RMSE Loss: 0.0361
2023-05-14 01:26:15,668 seq2seq.trainer.supervised_trainer INFO     Progress: 64%, Train RMSE Loss: 0.0352
2023-05-14 01:26:26,631 seq2seq.trainer.supervised_trainer INFO     Progress: 65%, Train RMSE Loss: 0.0341
2023-05-14 01:26:37,451 seq2seq.trainer.supervised_trainer INFO     Progress: 67%, Train RMSE Loss: 0.0360
2023-05-14 01:26:47,778 seq2seq.trainer.supervised_trainer INFO     Progress: 69%, Train RMSE Loss: 0.0381
2023-05-14 01:27:26,424 seq2seq.trainer.supervised_trainer INFO     
Finished epoch 7: Train RMSE Loss: 0.0357, Dev RMSE Loss: 0.1524, Test RMSE Loss: 0.1537
2023-05-14 01:27:31,929 seq2seq.trainer.supervised_trainer INFO     Progress: 70%, Train RMSE Loss: 0.0349
2023-05-14 01:27:42,255 seq2seq.trainer.supervised_trainer INFO     Progress: 72%, Train RMSE Loss: 0.0361
2023-05-14 01:27:52,005 seq2seq.trainer.supervised_trainer INFO     Progress: 74%, Train RMSE Loss: 0.0332
2023-05-14 01:28:03,151 seq2seq.trainer.supervised_trainer INFO     Progress: 75%, Train RMSE Loss: 0.0361
2023-05-14 01:28:14,590 seq2seq.trainer.supervised_trainer INFO     Progress: 77%, Train RMSE Loss: 0.0352
2023-05-14 01:28:25,640 seq2seq.trainer.supervised_trainer INFO     Progress: 78%, Train RMSE Loss: 0.0344
2023-05-14 01:29:03,334 seq2seq.trainer.supervised_trainer INFO     
Finished epoch 8: Train RMSE Loss: 0.0352, Dev RMSE Loss: 0.1519, Test RMSE Loss: 0.1533
2023-05-14 01:29:07,277 seq2seq.trainer.supervised_trainer INFO     Progress: 80%, Train RMSE Loss: 0.0359
2023-05-14 01:29:18,401 seq2seq.trainer.supervised_trainer INFO     Progress: 82%, Train RMSE Loss: 0.0346
2023-05-14 01:29:29,374 seq2seq.trainer.supervised_trainer INFO     Progress: 83%, Train RMSE Loss: 0.0341
2023-05-14 01:29:40,089 seq2seq.trainer.supervised_trainer INFO     Progress: 85%, Train RMSE Loss: 0.0350
2023-05-14 01:29:51,081 seq2seq.trainer.supervised_trainer INFO     Progress: 87%, Train RMSE Loss: 0.0357
2023-05-14 01:30:02,529 seq2seq.trainer.supervised_trainer INFO     Progress: 88%, Train RMSE Loss: 0.0359
2023-05-14 01:30:40,806 seq2seq.trainer.supervised_trainer INFO     
Finished epoch 9: Train RMSE Loss: 0.0353, Dev RMSE Loss: 0.1473, Test RMSE Loss: 0.1486
2023-05-14 01:30:44,108 seq2seq.trainer.supervised_trainer INFO     Progress: 90%, Train RMSE Loss: 0.0360
2023-05-14 01:30:55,125 seq2seq.trainer.supervised_trainer INFO     Progress: 92%, Train RMSE Loss: 0.0359
2023-05-14 01:31:06,334 seq2seq.trainer.supervised_trainer INFO     Progress: 93%, Train RMSE Loss: 0.0350
2023-05-14 01:31:17,041 seq2seq.trainer.supervised_trainer INFO     Progress: 95%, Train RMSE Loss: 0.0356
2023-05-14 01:31:27,486 seq2seq.trainer.supervised_trainer INFO     Progress: 97%, Train RMSE Loss: 0.0367
2023-05-14 01:31:37,749 seq2seq.trainer.supervised_trainer INFO     Progress: 98%, Train RMSE Loss: 0.0355
2023-05-14 01:33:21,811 seq2seq.trainer.supervised_trainer INFO     
Finished epoch 10: Train RMSE Loss: 0.0356, Dev RMSE Loss: 0.1455, Test RMSE Loss: 0.1468
Train RMSE Loss from Evaluator: 0.1462
------Hyper-parameters------
model_name: cnn, batch_size: 64, hidden_size: 32, learning_rate: 0.001, num_epochs: 10, num_layers: 3, dropout_rate: 0.1, teacher_forcing_ratio: 0.5
input_size: 128, kernel_size: 3, num_head: 2, use_adamw: False
use_sbert = False, use_sbert_seq = False, in_len: 4, out_len: 5
----------------------------
--------------Best Model:--------------
Epoch 2, Train RMSE Loss: 0.1412, Dev RMSE Loss: 0.1405, Test RMSE Loss: 0.1468
---------------------------------------
