2023-05-14 00:58:53,122 root         INFO     Namespace(data_path='do', expt_dir='./experiment/baseline_rnn', log_level='info', model='rnn')
2023-05-14 00:58:53,122 sentence_transformers.SentenceTransformer INFO     Load pretrained SentenceTransformer: all-MiniLM-L6-v2
2023-05-14 00:58:53,902 sentence_transformers.SentenceTransformer INFO     Use pytorch device: cuda
2023-05-14 00:58:56,163 seq2seq.trainer.supervised_trainer INFO     Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
), Scheduler: None
2023-05-14 00:59:08,634 seq2seq.trainer.supervised_trainer INFO     Progress: 3%, Train RMSE Loss: 0.0363
2023-05-14 00:59:13,956 seq2seq.trainer.supervised_trainer INFO     Progress: 4%, Train RMSE Loss: 0.0086
2023-05-14 00:59:18,665 seq2seq.trainer.supervised_trainer INFO     Progress: 6%, Train RMSE Loss: 0.0090
2023-05-14 00:59:23,438 seq2seq.trainer.supervised_trainer INFO     Progress: 8%, Train RMSE Loss: 0.0081
2023-05-14 00:59:28,244 seq2seq.trainer.supervised_trainer INFO     Progress: 9%, Train RMSE Loss: 0.0070
2023-05-14 00:59:37,140 seq2seq.trainer.supervised_trainer INFO     
Finished epoch 1: Train RMSE Loss: 0.0114, Dev RMSE Loss: 0.1397, Test RMSE Loss: 0.1396
2023-05-14 00:59:42,017 seq2seq.trainer.supervised_trainer INFO     Progress: 11%, Train RMSE Loss: 0.0076
2023-05-14 00:59:47,027 seq2seq.trainer.supervised_trainer INFO     Progress: 13%, Train RMSE Loss: 0.0069
2023-05-14 00:59:51,940 seq2seq.trainer.supervised_trainer INFO     Progress: 14%, Train RMSE Loss: 0.0065
2023-05-14 00:59:56,930 seq2seq.trainer.supervised_trainer INFO     Progress: 16%, Train RMSE Loss: 0.0063
2023-05-14 01:00:02,040 seq2seq.trainer.supervised_trainer INFO     Progress: 18%, Train RMSE Loss: 0.0059
2023-05-14 01:00:07,007 seq2seq.trainer.supervised_trainer INFO     Progress: 19%, Train RMSE Loss: 0.0057
2023-05-14 01:00:16,040 seq2seq.trainer.supervised_trainer INFO     
Finished epoch 2: Train RMSE Loss: 0.0065, Dev RMSE Loss: 0.1661, Test RMSE Loss: 0.1660
2023-05-14 01:00:20,281 seq2seq.trainer.supervised_trainer INFO     Progress: 21%, Train RMSE Loss: 0.0059
2023-05-14 01:00:25,320 seq2seq.trainer.supervised_trainer INFO     Progress: 23%, Train RMSE Loss: 0.0060
2023-05-14 01:00:30,028 seq2seq.trainer.supervised_trainer INFO     Progress: 24%, Train RMSE Loss: 0.0056
2023-05-14 01:00:34,771 seq2seq.trainer.supervised_trainer INFO     Progress: 26%, Train RMSE Loss: 0.0060
2023-05-14 01:00:39,518 seq2seq.trainer.supervised_trainer INFO     Progress: 27%, Train RMSE Loss: 0.0054
2023-05-14 01:00:44,288 seq2seq.trainer.supervised_trainer INFO     Progress: 29%, Train RMSE Loss: 0.0051
2023-05-14 01:00:53,912 seq2seq.trainer.supervised_trainer INFO     
Finished epoch 3: Train RMSE Loss: 0.0057, Dev RMSE Loss: 0.1295, Test RMSE Loss: 0.1295
2023-05-14 01:00:57,819 seq2seq.trainer.supervised_trainer INFO     Progress: 31%, Train RMSE Loss: 0.0053
2023-05-14 01:01:02,717 seq2seq.trainer.supervised_trainer INFO     Progress: 32%, Train RMSE Loss: 0.0051
2023-05-14 01:01:07,622 seq2seq.trainer.supervised_trainer INFO     Progress: 34%, Train RMSE Loss: 0.0052
2023-05-14 01:01:12,903 seq2seq.trainer.supervised_trainer INFO     Progress: 36%, Train RMSE Loss: 0.0051
2023-05-14 01:01:17,726 seq2seq.trainer.supervised_trainer INFO     Progress: 37%, Train RMSE Loss: 0.0051
2023-05-14 01:01:22,606 seq2seq.trainer.supervised_trainer INFO     Progress: 39%, Train RMSE Loss: 0.0053
2023-05-14 01:01:32,675 seq2seq.trainer.supervised_trainer INFO     
Finished epoch 4: Train RMSE Loss: 0.0051, Dev RMSE Loss: 0.1198, Test RMSE Loss: 0.1197
2023-05-14 01:01:36,156 seq2seq.trainer.supervised_trainer INFO     Progress: 41%, Train RMSE Loss: 0.0048
2023-05-14 01:01:40,875 seq2seq.trainer.supervised_trainer INFO     Progress: 42%, Train RMSE Loss: 0.0047
2023-05-14 01:01:45,623 seq2seq.trainer.supervised_trainer INFO     Progress: 44%, Train RMSE Loss: 0.0046
2023-05-14 01:01:50,441 seq2seq.trainer.supervised_trainer INFO     Progress: 46%, Train RMSE Loss: 0.0049
2023-05-14 01:01:55,499 seq2seq.trainer.supervised_trainer INFO     Progress: 47%, Train RMSE Loss: 0.0050
2023-05-14 01:02:00,255 seq2seq.trainer.supervised_trainer INFO     Progress: 49%, Train RMSE Loss: 0.0046
2023-05-14 01:02:10,176 seq2seq.trainer.supervised_trainer INFO     
Finished epoch 5: Train RMSE Loss: 0.0048, Dev RMSE Loss: 0.1387, Test RMSE Loss: 0.1387
2023-05-14 01:02:13,327 seq2seq.trainer.supervised_trainer INFO     Progress: 51%, Train RMSE Loss: 0.0050
2023-05-14 01:02:18,142 seq2seq.trainer.supervised_trainer INFO     Progress: 52%, Train RMSE Loss: 0.0044
2023-05-14 01:02:22,951 seq2seq.trainer.supervised_trainer INFO     Progress: 54%, Train RMSE Loss: 0.0050
2023-05-14 01:02:27,786 seq2seq.trainer.supervised_trainer INFO     Progress: 55%, Train RMSE Loss: 0.0048
2023-05-14 01:02:32,487 seq2seq.trainer.supervised_trainer INFO     Progress: 57%, Train RMSE Loss: 0.0048
2023-05-14 01:02:37,073 seq2seq.trainer.supervised_trainer INFO     Progress: 59%, Train RMSE Loss: 0.0044
2023-05-14 01:02:47,701 seq2seq.trainer.supervised_trainer INFO     
Finished epoch 6: Train RMSE Loss: 0.0047, Dev RMSE Loss: 0.1532, Test RMSE Loss: 0.1532
2023-05-14 01:02:50,380 seq2seq.trainer.supervised_trainer INFO     Progress: 60%, Train RMSE Loss: 0.0045
2023-05-14 01:02:54,634 seq2seq.trainer.supervised_trainer INFO     Progress: 62%, Train RMSE Loss: 0.0041
2023-05-14 01:02:58,634 seq2seq.trainer.supervised_trainer INFO     Progress: 64%, Train RMSE Loss: 0.0047
2023-05-14 01:03:02,607 seq2seq.trainer.supervised_trainer INFO     Progress: 65%, Train RMSE Loss: 0.0046
2023-05-14 01:03:06,616 seq2seq.trainer.supervised_trainer INFO     Progress: 67%, Train RMSE Loss: 0.0045
2023-05-14 01:03:10,731 seq2seq.trainer.supervised_trainer INFO     Progress: 69%, Train RMSE Loss: 0.0042
2023-05-14 01:03:19,726 seq2seq.trainer.supervised_trainer INFO     
Finished epoch 7: Train RMSE Loss: 0.0044, Dev RMSE Loss: 0.1353, Test RMSE Loss: 0.1355
2023-05-14 01:03:21,718 seq2seq.trainer.supervised_trainer INFO     Progress: 70%, Train RMSE Loss: 0.0047
2023-05-14 01:03:25,682 seq2seq.trainer.supervised_trainer INFO     Progress: 72%, Train RMSE Loss: 0.0043
2023-05-14 01:03:29,973 seq2seq.trainer.supervised_trainer INFO     Progress: 74%, Train RMSE Loss: 0.0039
2023-05-14 01:03:33,953 seq2seq.trainer.supervised_trainer INFO     Progress: 75%, Train RMSE Loss: 0.0041
2023-05-14 01:03:37,957 seq2seq.trainer.supervised_trainer INFO     Progress: 77%, Train RMSE Loss: 0.0047
2023-05-14 01:03:41,924 seq2seq.trainer.supervised_trainer INFO     Progress: 78%, Train RMSE Loss: 0.0043
2023-05-14 01:03:51,201 seq2seq.trainer.supervised_trainer INFO     
Finished epoch 8: Train RMSE Loss: 0.0043, Dev RMSE Loss: 0.1346, Test RMSE Loss: 0.1347
2023-05-14 01:03:52,888 seq2seq.trainer.supervised_trainer INFO     Progress: 80%, Train RMSE Loss: 0.0042
2023-05-14 01:03:56,857 seq2seq.trainer.supervised_trainer INFO     Progress: 82%, Train RMSE Loss: 0.0043
2023-05-14 01:04:00,830 seq2seq.trainer.supervised_trainer INFO     Progress: 83%, Train RMSE Loss: 0.0046
2023-05-14 01:04:04,853 seq2seq.trainer.supervised_trainer INFO     Progress: 85%, Train RMSE Loss: 0.0042
2023-05-14 01:04:08,823 seq2seq.trainer.supervised_trainer INFO     Progress: 87%, Train RMSE Loss: 0.0037
2023-05-14 01:04:13,064 seq2seq.trainer.supervised_trainer INFO     Progress: 88%, Train RMSE Loss: 0.0040
2023-05-14 01:04:22,790 seq2seq.trainer.supervised_trainer INFO     
Finished epoch 9: Train RMSE Loss: 0.0042, Dev RMSE Loss: 0.1200, Test RMSE Loss: 0.1200
2023-05-14 01:04:24,196 seq2seq.trainer.supervised_trainer INFO     Progress: 90%, Train RMSE Loss: 0.0040
2023-05-14 01:04:28,185 seq2seq.trainer.supervised_trainer INFO     Progress: 92%, Train RMSE Loss: 0.0041
2023-05-14 01:04:32,198 seq2seq.trainer.supervised_trainer INFO     Progress: 93%, Train RMSE Loss: 0.0039
2023-05-14 01:04:36,184 seq2seq.trainer.supervised_trainer INFO     Progress: 95%, Train RMSE Loss: 0.0039
2023-05-14 01:04:40,128 seq2seq.trainer.supervised_trainer INFO     Progress: 97%, Train RMSE Loss: 0.0038
2023-05-14 01:04:44,111 seq2seq.trainer.supervised_trainer INFO     Progress: 98%, Train RMSE Loss: 0.0037
2023-05-14 01:05:10,026 seq2seq.trainer.supervised_trainer INFO     
Finished epoch 10: Train RMSE Loss: 0.0039, Dev RMSE Loss: 0.1292, Test RMSE Loss: 0.1293
Train RMSE Loss from Evaluator: 0.1298
------Hyper-parameters------
model_name: rnn, batch_size: 64, hidden_size: 32, learning_rate: 0.001, num_epochs: 10, num_layers: 3, dropout_rate: 0.1, teacher_forcing_ratio: 1
input_size: 128, kernel_size: 3, num_head: 2, use_adamw: False
use_sbert = False, use_sbert_seq = False, in_len: 5, out_len: 5
----------------------------
--------------Best Model:--------------
Epoch 4, Train RMSE Loss: 0.1201, Dev RMSE Loss: 0.1198, Test RMSE Loss: 0.1293
---------------------------------------
