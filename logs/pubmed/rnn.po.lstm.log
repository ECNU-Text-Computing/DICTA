2023-05-14 00:46:56,698 root         INFO     Namespace(data_path='po', expt_dir='./experiment/no_att_abs', log_level='info', model='rnn')
2023-05-14 00:46:56,698 sentence_transformers.SentenceTransformer INFO     Load pretrained SentenceTransformer: all-MiniLM-L6-v2
2023-05-14 00:46:57,066 sentence_transformers.SentenceTransformer INFO     Use pytorch device: cuda
2023-05-14 00:46:58,983 seq2seq.trainer.supervised_trainer INFO     Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
), Scheduler: None
2023-05-14 00:47:08,210 seq2seq.trainer.supervised_trainer INFO     Progress: 5%, Train RMSE Loss: 0.0354
2023-05-14 00:47:13,201 seq2seq.trainer.supervised_trainer INFO     Progress: 8%, Train RMSE Loss: 0.0084
2023-05-14 00:47:19,819 seq2seq.trainer.supervised_trainer INFO     
Finished epoch 1: Train RMSE Loss: 0.0138, Dev RMSE Loss: 0.2266, Test RMSE Loss: 0.2266
2023-05-14 00:47:23,119 seq2seq.trainer.supervised_trainer INFO     Progress: 11%, Train RMSE Loss: 0.0073
2023-05-14 00:47:27,833 seq2seq.trainer.supervised_trainer INFO     Progress: 14%, Train RMSE Loss: 0.0084
2023-05-14 00:47:32,587 seq2seq.trainer.supervised_trainer INFO     Progress: 17%, Train RMSE Loss: 0.0078
2023-05-14 00:47:40,491 seq2seq.trainer.supervised_trainer INFO     
Finished epoch 2: Train RMSE Loss: 0.0076, Dev RMSE Loss: 0.2503, Test RMSE Loss: 0.2503
2023-05-14 00:47:42,071 seq2seq.trainer.supervised_trainer INFO     Progress: 20%, Train RMSE Loss: 0.0063
2023-05-14 00:47:46,995 seq2seq.trainer.supervised_trainer INFO     Progress: 23%, Train RMSE Loss: 0.0066
2023-05-14 00:47:51,785 seq2seq.trainer.supervised_trainer INFO     Progress: 26%, Train RMSE Loss: 0.0072
2023-05-14 00:47:56,560 seq2seq.trainer.supervised_trainer INFO     Progress: 29%, Train RMSE Loss: 0.0061
2023-05-14 00:48:01,581 seq2seq.trainer.supervised_trainer INFO     
Finished epoch 3: Train RMSE Loss: 0.0066, Dev RMSE Loss: 0.2530, Test RMSE Loss: 0.2530
2023-05-14 00:48:06,269 seq2seq.trainer.supervised_trainer INFO     Progress: 32%, Train RMSE Loss: 0.0059
2023-05-14 00:48:11,110 seq2seq.trainer.supervised_trainer INFO     Progress: 35%, Train RMSE Loss: 0.0056
2023-05-14 00:48:15,834 seq2seq.trainer.supervised_trainer INFO     Progress: 38%, Train RMSE Loss: 0.0055
2023-05-14 00:48:22,570 seq2seq.trainer.supervised_trainer INFO     
Finished epoch 4: Train RMSE Loss: 0.0056, Dev RMSE Loss: 0.2872, Test RMSE Loss: 0.2872
2023-05-14 00:48:25,500 seq2seq.trainer.supervised_trainer INFO     Progress: 41%, Train RMSE Loss: 0.0054
2023-05-14 00:48:30,249 seq2seq.trainer.supervised_trainer INFO     Progress: 44%, Train RMSE Loss: 0.0061
2023-05-14 00:48:34,910 seq2seq.trainer.supervised_trainer INFO     Progress: 47%, Train RMSE Loss: 0.0057
2023-05-14 00:48:43,307 seq2seq.trainer.supervised_trainer INFO     
Finished epoch 5: Train RMSE Loss: 0.0056, Dev RMSE Loss: 0.2832, Test RMSE Loss: 0.2832
2023-05-14 00:48:44,541 seq2seq.trainer.supervised_trainer INFO     Progress: 50%, Train RMSE Loss: 0.0052
2023-05-14 00:48:49,230 seq2seq.trainer.supervised_trainer INFO     Progress: 53%, Train RMSE Loss: 0.0056
2023-05-14 00:48:53,836 seq2seq.trainer.supervised_trainer INFO     Progress: 56%, Train RMSE Loss: 0.0056
2023-05-14 00:48:58,665 seq2seq.trainer.supervised_trainer INFO     Progress: 59%, Train RMSE Loss: 0.0052
2023-05-14 00:49:04,003 seq2seq.trainer.supervised_trainer INFO     
Finished epoch 6: Train RMSE Loss: 0.0054, Dev RMSE Loss: 0.2915, Test RMSE Loss: 0.2916
2023-05-14 00:49:08,236 seq2seq.trainer.supervised_trainer INFO     Progress: 62%, Train RMSE Loss: 0.0048
2023-05-14 00:49:12,906 seq2seq.trainer.supervised_trainer INFO     Progress: 65%, Train RMSE Loss: 0.0055
2023-05-14 00:49:17,572 seq2seq.trainer.supervised_trainer INFO     Progress: 68%, Train RMSE Loss: 0.0047
2023-05-14 00:49:24,716 seq2seq.trainer.supervised_trainer INFO     
Finished epoch 7: Train RMSE Loss: 0.0049, Dev RMSE Loss: 0.2918, Test RMSE Loss: 0.2920
2023-05-14 00:49:27,336 seq2seq.trainer.supervised_trainer INFO     Progress: 71%, Train RMSE Loss: 0.0045
2023-05-14 00:49:32,131 seq2seq.trainer.supervised_trainer INFO     Progress: 74%, Train RMSE Loss: 0.0043
2023-05-14 00:49:36,707 seq2seq.trainer.supervised_trainer INFO     Progress: 77%, Train RMSE Loss: 0.0053
2023-05-14 00:49:45,431 seq2seq.trainer.supervised_trainer INFO     
Finished epoch 8: Train RMSE Loss: 0.0048, Dev RMSE Loss: 0.2848, Test RMSE Loss: 0.2849
2023-05-14 00:49:46,329 seq2seq.trainer.supervised_trainer INFO     Progress: 80%, Train RMSE Loss: 0.0048
2023-05-14 00:49:51,272 seq2seq.trainer.supervised_trainer INFO     Progress: 83%, Train RMSE Loss: 0.0048
2023-05-14 00:49:56,049 seq2seq.trainer.supervised_trainer INFO     Progress: 86%, Train RMSE Loss: 0.0045
2023-05-14 00:50:00,705 seq2seq.trainer.supervised_trainer INFO     Progress: 89%, Train RMSE Loss: 0.0044
2023-05-14 00:50:06,621 seq2seq.trainer.supervised_trainer INFO     
Finished epoch 9: Train RMSE Loss: 0.0046, Dev RMSE Loss: 0.3021, Test RMSE Loss: 0.3024
2023-05-14 00:50:10,579 seq2seq.trainer.supervised_trainer INFO     Progress: 92%, Train RMSE Loss: 0.0045
2023-05-14 00:50:15,245 seq2seq.trainer.supervised_trainer INFO     Progress: 95%, Train RMSE Loss: 0.0043
2023-05-14 00:50:20,003 seq2seq.trainer.supervised_trainer INFO     Progress: 98%, Train RMSE Loss: 0.0043
2023-05-14 00:50:38,523 seq2seq.trainer.supervised_trainer INFO     
Finished epoch 10: Train RMSE Loss: 0.0043, Dev RMSE Loss: 0.2926, Test RMSE Loss: 0.2927
Train RMSE Loss from Evaluator: 0.2927
------Hyper-parameters------
model_name: rnn, batch_size: 64, hidden_size: 32, learning_rate: 0.001, num_epochs: 10, num_layers: 3, dropout_rate: 0.1, teacher_forcing_ratio: 1
input_size: 128, kernel_size: 3, num_head: 2, use_adamw: False
use_sbert = False, use_sbert_seq = False, in_len: 5, out_len: 5
----------------------------
--------------Best Model:--------------
Epoch 1, Train RMSE Loss: 0.2260, Dev RMSE Loss: 0.2266, Test RMSE Loss: 0.2927
---------------------------------------
