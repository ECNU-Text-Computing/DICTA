2023-05-14 00:58:46,345 root         INFO     Namespace(data_path='po', expt_dir='./experiment/baseline_rnn', log_level='info', model='rnn')
2023-05-14 00:58:46,345 sentence_transformers.SentenceTransformer INFO     Load pretrained SentenceTransformer: all-MiniLM-L6-v2
2023-05-14 00:58:47,108 sentence_transformers.SentenceTransformer INFO     Use pytorch device: cuda
2023-05-14 00:58:49,242 seq2seq.trainer.supervised_trainer INFO     Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
), Scheduler: None
2023-05-14 00:59:00,653 seq2seq.trainer.supervised_trainer INFO     Progress: 5%, Train RMSE Loss: 0.0321
2023-05-14 00:59:06,388 seq2seq.trainer.supervised_trainer INFO     Progress: 8%, Train RMSE Loss: 0.0099
2023-05-14 00:59:14,055 seq2seq.trainer.supervised_trainer INFO     
Finished epoch 1: Train RMSE Loss: 0.0135, Dev RMSE Loss: 0.2103, Test RMSE Loss: 0.2103
2023-05-14 00:59:17,394 seq2seq.trainer.supervised_trainer INFO     Progress: 11%, Train RMSE Loss: 0.0096
2023-05-14 00:59:22,179 seq2seq.trainer.supervised_trainer INFO     Progress: 14%, Train RMSE Loss: 0.0087
2023-05-14 00:59:27,021 seq2seq.trainer.supervised_trainer INFO     Progress: 17%, Train RMSE Loss: 0.0085
2023-05-14 00:59:35,290 seq2seq.trainer.supervised_trainer INFO     
Finished epoch 2: Train RMSE Loss: 0.0087, Dev RMSE Loss: 0.1885, Test RMSE Loss: 0.1884
2023-05-14 00:59:36,873 seq2seq.trainer.supervised_trainer INFO     Progress: 20%, Train RMSE Loss: 0.0080
2023-05-14 00:59:41,735 seq2seq.trainer.supervised_trainer INFO     Progress: 23%, Train RMSE Loss: 0.0083
2023-05-14 00:59:46,691 seq2seq.trainer.supervised_trainer INFO     Progress: 26%, Train RMSE Loss: 0.0072
2023-05-14 00:59:51,575 seq2seq.trainer.supervised_trainer INFO     Progress: 29%, Train RMSE Loss: 0.0072
2023-05-14 00:59:56,753 seq2seq.trainer.supervised_trainer INFO     
Finished epoch 3: Train RMSE Loss: 0.0077, Dev RMSE Loss: 0.1938, Test RMSE Loss: 0.1935
2023-05-14 01:00:01,712 seq2seq.trainer.supervised_trainer INFO     Progress: 32%, Train RMSE Loss: 0.0069
2023-05-14 01:00:06,681 seq2seq.trainer.supervised_trainer INFO     Progress: 35%, Train RMSE Loss: 0.0077
2023-05-14 01:00:11,545 seq2seq.trainer.supervised_trainer INFO     Progress: 38%, Train RMSE Loss: 0.0075
2023-05-14 01:00:18,284 seq2seq.trainer.supervised_trainer INFO     
Finished epoch 4: Train RMSE Loss: 0.0074, Dev RMSE Loss: 0.1820, Test RMSE Loss: 0.1814
2023-05-14 01:00:21,370 seq2seq.trainer.supervised_trainer INFO     Progress: 41%, Train RMSE Loss: 0.0076
2023-05-14 01:00:26,279 seq2seq.trainer.supervised_trainer INFO     Progress: 44%, Train RMSE Loss: 0.0068
2023-05-14 01:00:30,976 seq2seq.trainer.supervised_trainer INFO     Progress: 47%, Train RMSE Loss: 0.0067
2023-05-14 01:00:39,487 seq2seq.trainer.supervised_trainer INFO     
Finished epoch 5: Train RMSE Loss: 0.0070, Dev RMSE Loss: 0.2001, Test RMSE Loss: 0.1995
2023-05-14 01:00:40,780 seq2seq.trainer.supervised_trainer INFO     Progress: 50%, Train RMSE Loss: 0.0074
2023-05-14 01:00:45,570 seq2seq.trainer.supervised_trainer INFO     Progress: 53%, Train RMSE Loss: 0.0064
2023-05-14 01:00:50,308 seq2seq.trainer.supervised_trainer INFO     Progress: 56%, Train RMSE Loss: 0.0061
2023-05-14 01:00:54,972 seq2seq.trainer.supervised_trainer INFO     Progress: 59%, Train RMSE Loss: 0.0062
2023-05-14 01:01:00,406 seq2seq.trainer.supervised_trainer INFO     
Finished epoch 6: Train RMSE Loss: 0.0063, Dev RMSE Loss: 0.1980, Test RMSE Loss: 0.1974
2023-05-14 01:01:04,838 seq2seq.trainer.supervised_trainer INFO     Progress: 62%, Train RMSE Loss: 0.0059
2023-05-14 01:01:10,046 seq2seq.trainer.supervised_trainer INFO     Progress: 65%, Train RMSE Loss: 0.0057
2023-05-14 01:01:14,965 seq2seq.trainer.supervised_trainer INFO     Progress: 68%, Train RMSE Loss: 0.0060
2023-05-14 01:01:22,162 seq2seq.trainer.supervised_trainer INFO     
Finished epoch 7: Train RMSE Loss: 0.0058, Dev RMSE Loss: 0.1945, Test RMSE Loss: 0.1938
2023-05-14 01:01:24,835 seq2seq.trainer.supervised_trainer INFO     Progress: 71%, Train RMSE Loss: 0.0058
2023-05-14 01:01:29,446 seq2seq.trainer.supervised_trainer INFO     Progress: 74%, Train RMSE Loss: 0.0060
2023-05-14 01:01:34,133 seq2seq.trainer.supervised_trainer INFO     Progress: 77%, Train RMSE Loss: 0.0056
2023-05-14 01:01:42,960 seq2seq.trainer.supervised_trainer INFO     
Finished epoch 8: Train RMSE Loss: 0.0057, Dev RMSE Loss: 0.1961, Test RMSE Loss: 0.1954
2023-05-14 01:01:43,882 seq2seq.trainer.supervised_trainer INFO     Progress: 80%, Train RMSE Loss: 0.0055
2023-05-14 01:01:48,686 seq2seq.trainer.supervised_trainer INFO     Progress: 83%, Train RMSE Loss: 0.0055
2023-05-14 01:01:53,762 seq2seq.trainer.supervised_trainer INFO     Progress: 86%, Train RMSE Loss: 0.0052
2023-05-14 01:01:58,573 seq2seq.trainer.supervised_trainer INFO     Progress: 89%, Train RMSE Loss: 0.0061
2023-05-14 01:02:04,359 seq2seq.trainer.supervised_trainer INFO     
Finished epoch 9: Train RMSE Loss: 0.0057, Dev RMSE Loss: 0.1791, Test RMSE Loss: 0.1784
2023-05-14 01:02:08,179 seq2seq.trainer.supervised_trainer INFO     Progress: 92%, Train RMSE Loss: 0.0055
2023-05-14 01:02:12,851 seq2seq.trainer.supervised_trainer INFO     Progress: 95%, Train RMSE Loss: 0.0055
2023-05-14 01:02:17,658 seq2seq.trainer.supervised_trainer INFO     Progress: 98%, Train RMSE Loss: 0.0054
2023-05-14 01:02:36,207 seq2seq.trainer.supervised_trainer INFO     
Finished epoch 10: Train RMSE Loss: 0.0054, Dev RMSE Loss: 0.1966, Test RMSE Loss: 0.1960
Train RMSE Loss from Evaluator: 0.1954
------Hyper-parameters------
model_name: rnn, batch_size: 64, hidden_size: 32, learning_rate: 0.001, num_epochs: 10, num_layers: 3, dropout_rate: 0.1, teacher_forcing_ratio: 1
input_size: 128, kernel_size: 3, num_head: 2, use_adamw: False
use_sbert = False, use_sbert_seq = False, in_len: 5, out_len: 5
----------------------------
--------------Best Model:--------------
Epoch 9, Train RMSE Loss: 0.1782, Dev RMSE Loss: 0.1791, Test RMSE Loss: 0.1960
---------------------------------------
